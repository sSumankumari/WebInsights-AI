{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sSumankumari/WebInsights-Tool/blob/main/notebooks/TextLoaders_and_TextSplitters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e36a1d5",
      "metadata": {
        "id": "8e36a1d5"
      },
      "source": [
        "# Document Loaders in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "519ff2e7",
      "metadata": {
        "id": "519ff2e7"
      },
      "source": [
        "## Text Loaders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "id": "T9Ln_d41u1EB",
        "outputId": "3fa0896e-5161-4d00-b887-7ea3612fd055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "id": "T9Ln_d41u1EB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a7de832-32fc-4f02-ac90-6186cb7d04ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a7de832-32fc-4f02-ac90-6186cb7d04ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nvda_news_1.txt to nvda_news_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "LaxpITFmvlIV",
        "outputId": "28f19aea-cba5-4f88-82ed-c40b0648e45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LaxpITFmvlIV",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.6)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4a6e691a",
      "metadata": {
        "id": "4a6e691a",
        "outputId": "18200d17-145c-4135-a6e5-7eb16b5abc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'nvda_news_1.txt'}, page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"nvda_news_1.txt\")\n",
        "loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cf1ab850",
      "metadata": {
        "id": "cf1ab850",
        "outputId": "99002b8a-73ec-403c-8117-c4c5c2d32dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_community.document_loaders.text.TextLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_community.document_loaders.text.TextLoader</b><br/>def __init__(file_path: Union[str, Path], encoding: Optional[str]=None, autodetect_encoding: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/text.py</a>Load text file.\n",
              "\n",
              "\n",
              "Args:\n",
              "    file_path: Path to the file to load.\n",
              "\n",
              "    encoding: File encoding to use. If `None`, the file will be loaded\n",
              "    with the default system encoding.\n",
              "\n",
              "    autodetect_encoding: Whether to try to autodetect the file encoding\n",
              "        if the specified encoding fails.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 13);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "addd2e10",
      "metadata": {
        "id": "addd2e10",
        "outputId": "af1749a8-f6b2-485f-b581-7a3655292554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nvda_news_1.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "loader.file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490aecbe",
      "metadata": {
        "id": "490aecbe"
      },
      "source": [
        "### CSV Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8f5be337",
      "metadata": {
        "id": "8f5be337"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.csv_loader import CSVLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "id": "9KMe_Hqsv3LP",
        "outputId": "56e79796-4d88-412a-e3b8-2fd1ae1f6f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "id": "9KMe_Hqsv3LP",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6af3548-09be-4c2c-9fa9-75247b26edc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6af3548-09be-4c2c-9fa9-75247b26edc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving movies.csv to movies.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8614f3ee",
      "metadata": {
        "id": "8614f3ee",
        "outputId": "7f3b210b-ba40-4862-cfe0-417980b9d1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'movies.csv', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 1}, page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 2}, page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 3}, page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 4}, page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 5}, page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 6}, page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 7}, page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR'),\n",
              " Document(metadata={'source': 'movies.csv', 'row': 8}, page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "loader = CSVLoader(file_path=\"movies.csv\")\n",
        "\n",
        "data = loader.load()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ea307db8",
      "metadata": {
        "id": "ea307db8",
        "outputId": "bf3b68ea-5d00-45f2-925c-4c12f6047b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'movies.csv', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7e3c9488",
      "metadata": {
        "id": "7e3c9488",
        "outputId": "f5844e59-1202-4a28-fd0d-dbecf073f740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'K.G.F: Chapter 2', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'),\n",
              " Document(metadata={'source': 'Doctor Strange in the Multiverse of Madness', 'row': 1}, page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'Thor: The Dark World', 'row': 2}, page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'Thor: Ragnarok', 'row': 3}, page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'Thor: Love and Thunder', 'row': 4}, page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD'),\n",
              " Document(metadata={'source': 'Sholay', 'row': 5}, page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'),\n",
              " Document(metadata={'source': 'Dilwale Dulhania Le Jayenge', 'row': 6}, page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR'),\n",
              " Document(metadata={'source': '3 Idiots', 'row': 7}, page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR'),\n",
              " Document(metadata={'source': 'Kabhi Khushi Kabhie Gham', 'row': 8}, page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "loader = CSVLoader(file_path=\"movies.csv\", source_column=\"title\")\n",
        "data = loader.load()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fbf67118",
      "metadata": {
        "id": "fbf67118",
        "outputId": "bd6f4c19-5b56-4811-9f26-5ee1afe00a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b6135f39",
      "metadata": {
        "id": "b6135f39",
        "outputId": "2d34295e-ff01-4264-ee04-f12a8170b672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'K.G.F: Chapter 2', 'row': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ac7b21",
      "metadata": {
        "id": "b3ac7b21"
      },
      "source": [
        "### Unstructured URL Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e7e716",
      "metadata": {
        "id": "48e7e716"
      },
      "source": [
        "UnstructuredURLLoader of Langchain internally uses unstructured python library to load the content from url's\n",
        "\n",
        "https://unstructured-io.github.io/unstructured/introduction.html\n",
        "\n",
        "https://pypi.org/project/unstructured/#description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cc46ff32",
      "metadata": {
        "id": "cc46ff32",
        "outputId": "4df2ab83-5775-446a-bce9-bd40a3554771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Using cached unstructured-0.16.4-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting libmagic\n",
            "  Using cached libmagic-1.0.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic\n",
            "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.26.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.2.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.2)\n",
            "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.9.2)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Downloading unstructured-0.16.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.26.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libmagic, langdetect\n",
            "  Building wheel for libmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4269 sha256=a1fa4be0f04759e27a88aacfa90a0297d7fc0f86eda0687ccd484a58c4c3a59e\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/ce/d8/099fbd4dbfa5da5596a39eee8a17d2e1bcc29006c07d3563b7\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=9d8ff985711a79128acb9e1a07e571da664505cb0616fe7f9e7ca4798d4152e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built libmagic langdetect\n",
            "Installing collected packages: libmagic, filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, langdetect, jsonpath-python, emoji, backoff, python-oxmsg, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 emoji-2.14.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 libmagic-1.0 olefile-0.47 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.1 unstructured-0.16.4 unstructured-client-0.26.2\n"
          ]
        }
      ],
      "source": [
        "# Installing necessary libraries, libmagic is used for file type detection\n",
        "!pip3 install unstructured libmagic python-magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5d1831d5",
      "metadata": {
        "id": "5d1831d5"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5e032cc0",
      "metadata": {
        "id": "5e032cc0",
        "outputId": "b81efb0e-cac7-4daa-c307-49d84a94a8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "\n",
        "import os\n",
        "\n",
        "# Set up custom NLTK data path\n",
        "nltk_data_dir = '/root/nltk_data'\n",
        "os.makedirs(nltk_data_dir, exist_ok=True)\n",
        "\n",
        "# Download punkt tokenizer to the custom directory\n",
        "nltk.download('punkt', download_dir=nltk_data_dir)\n",
        "\n",
        "# Configure NLTK to use the custom download directory\n",
        "nltk.data.path.append(nltk_data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "01d17c8b",
      "metadata": {
        "id": "01d17c8b"
      },
      "outputs": [],
      "source": [
        "# URLs to load\n",
        "urls = [\n",
        "    \"https://torontodigital.ca/blog/ai-chatbots-for-sentiment-analysis-understanding-customer-emotions/\",\n",
        "    \"https://quidget.ai/blog/ai-automation/5-benefits-of-sentiment-analysis-for-chatbots/\",\n",
        "    \"https://blog.hubspot.com/service/chatbot-sentiment-analysis\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "05b07afa",
      "metadata": {
        "id": "05b07afa",
        "outputId": "7785575b-9722-4dc0-fc40-aa9639ba3398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://torontodigital.ca/blog/ai-chatbots-for-sentiment-analysis-understanding-customer-emotions/, exception: No such file or directory: '/root/nltk_data/tokenizers/punkt/PY3_tab'\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://quidget.ai/blog/ai-automation/5-benefits-of-sentiment-analysis-for-chatbots/, exception: Invalid input object: NoneType\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://blog.hubspot.com/service/chatbot-sentiment-analysis, exception: No such file or directory: '/root/nltk_data/tokenizers/punkt/PY3_tab'\n"
          ]
        }
      ],
      "source": [
        "# Attempt to load documents individually\n",
        "docs = []\n",
        "for url in loader.urls:\n",
        "    try:\n",
        "        docs.extend(UnstructuredURLLoader(urls=[url]).load())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading document from {url}: {e}\")\n",
        "\n",
        "# Print results if successfully loaded\n",
        "for doc in docs:\n",
        "    print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "29f1640f",
      "metadata": {
        "id": "29f1640f",
        "outputId": "d3e2ed7e-1e20-4bfb-cd89-e9fc8df1b7d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://torontodigital.ca/blog/ai-chatbots-for-sentiment-analysis-understanding-customer-emotions/, exception: No such file or directory: '/root/nltk_data/tokenizers/punkt/PY3_tab'\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://quidget.ai/blog/ai-automation/5-benefits-of-sentiment-analysis-for-chatbots/, exception: Invalid input object: NoneType\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://blog.hubspot.com/service/chatbot-sentiment-analysis, exception: No such file or directory: '/root/nltk_data/tokenizers/punkt/PY3_tab'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "data = loader.load()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "89a982eb",
      "metadata": {
        "id": "89a982eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dbf667d4",
      "metadata": {
        "id": "dbf667d4"
      },
      "source": [
        "## Text Splitters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb4c3dc",
      "metadata": {
        "id": "6cb4c3dc"
      },
      "source": [
        "Why do we need text splitters in first place?\n",
        "\n",
        "LLM's have token limits. Hence we need to split the text which can be large into small chunks so that each chunk size is under the token limit. There are various text splitter classes in langchain that allows us to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5ab8a368",
      "metadata": {
        "id": "5ab8a368"
      },
      "outputs": [],
      "source": [
        "# Taking some random text from wikipedia\n",
        "\n",
        "text = \"\"\"Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
        "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
        "Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.\n",
        "\n",
        "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg.\n",
        "Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
        "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
        "Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\n",
        "\n",
        "Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews from critics and grossed over $677 million worldwide ($715 million after subsequent re-releases), making it the tenth-highest-grossing film of 2014.\n",
        "It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.[5][6][7] Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62849291",
      "metadata": {
        "id": "62849291"
      },
      "source": [
        "### Manual approach of splitting the text into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "dd507f4c",
      "metadata": {
        "id": "dd507f4c",
        "outputId": "3063b6b4-3807-4e86-a3b5-4f67fe1fed23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher N'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# suppose limit is 100\n",
        "text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "76ce2169",
      "metadata": {
        "id": "76ce2169",
        "outputId": "94784bff-5c3e-4bfc-891b-237db3bb9b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# When we want complete words and want to do this for entire text, may be we can use Python's split funciton\n",
        "\n",
        "words = text.split(\" \")\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b54ca14a",
      "metadata": {
        "id": "b54ca14a"
      },
      "outputs": [],
      "source": [
        "chunks = []\n",
        "\n",
        "s = \"\"\n",
        "for word in words:\n",
        "    s += word + \" \"\n",
        "    if len(s)>200:\n",
        "        chunks.append(s)\n",
        "        s = \"\"\n",
        "\n",
        "chunks.append(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "35085272",
      "metadata": {
        "id": "35085272",
        "outputId": "e545685a-6c86-4b0b-80dc-d91068108bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt ',\n",
              " 'Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in ']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "chunks[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab141e29",
      "metadata": {
        "id": "ab141e29"
      },
      "source": [
        "### Using text splitter class from langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efde1244",
      "metadata": {
        "id": "efde1244"
      },
      "source": [
        "#### CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "85d82675",
      "metadata": {
        "id": "85d82675"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c63eab3e",
      "metadata": {
        "id": "c63eab3e",
        "outputId": "d0217154-7585-4e61-d7dc-2c578057a908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 210, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 208, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 358, which is longer than the specified 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "chunks = splitter.split_text(text)\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "d3f7900c",
      "metadata": {
        "id": "d3f7900c",
        "outputId": "42d95dda-c603-4d2d-f5fa-e02e2b0fe9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "120\n",
            "210\n",
            "181\n",
            "197\n",
            "207\n",
            "128\n",
            "357\n",
            "253\n"
          ]
        }
      ],
      "source": [
        "for chunk in chunks:\n",
        "    print(len(chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90ecac6d",
      "metadata": {
        "id": "90ecac6d"
      },
      "source": [
        "As we can see, all though we gave 200 as a chunk size since the split was based on \\n, it ended up creating chunks that are bigger than size 200.\n",
        "\n",
        "Another class from Langchain can be used to recursively split the text based on a list of separators. This class is RecursiveTextSplitter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46bc134",
      "metadata": {
        "id": "c46bc134"
      },
      "source": [
        "#### RecursiveTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "580b772c",
      "metadata": {
        "id": "580b772c"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
        "    chunk_size = 200,  # size of each chunk to be created\n",
        "    chunk_overlap = 0, # size of overlap between chunks in order to maintain the context\n",
        "    length_function = len  # Function to calculate size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "f4e38b16",
      "metadata": {
        "id": "f4e38b16",
        "outputId": "2263c2c4-ff50-4386-d730-e45d79572282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "120\n",
            "199\n",
            "10\n",
            "181\n",
            "197\n",
            "198\n",
            "8\n",
            "128\n",
            "191\n",
            "165\n",
            "198\n",
            "54\n"
          ]
        }
      ],
      "source": [
        "chunks = recursive_splitter.split_text(text)\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(len(chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0136f2f2",
      "metadata": {
        "id": "0136f2f2"
      },
      "source": [
        "### Understand the formation of these chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "d3b9256e",
      "metadata": {
        "id": "d3b9256e",
        "outputId": "e8ebe779-d691-4d06-96b0-2ec4cdff7cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "first_split = text.split(\"\\n\\n\")[0]\n",
        "first_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "86370423",
      "metadata": {
        "id": "86370423",
        "outputId": "abf2a7c9-80ed-49b5-b9ca-979783c9725b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(first_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c18077fa",
      "metadata": {
        "id": "c18077fa"
      },
      "source": [
        "According to above, Recursive text splitter uses a list of separators, i.e.  separators = [\"\\n\\n\", \"\\n\", \".\"]\n",
        "\n",
        "So now it will first split using \\n\\n and then if the resulting chunk size is greater than the chunk_size parameter which is 200\n",
        "in our case, then it will use the next separator which is \\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "30851c40",
      "metadata": {
        "id": "30851c40",
        "outputId": "8788e8d8-732a-4c24-e651-352f1858f4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. ',\n",
              " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. ',\n",
              " 'Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "second_split = first_split.split(\"\\n\")\n",
        "second_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2521cff5",
      "metadata": {
        "id": "2521cff5",
        "outputId": "ddcc524c-f564-4e42-b346-1cd27e7072b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106\n",
            "121\n",
            "210\n"
          ]
        }
      ],
      "source": [
        "for split in second_split:\n",
        "    print(len(split))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ef7cea",
      "metadata": {
        "id": "f2ef7cea"
      },
      "source": [
        "Third split exceeds chunk size 200. Now it will further try to split that using the third separator which is ' ' (space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "591a7baf",
      "metadata": {
        "id": "591a7baf",
        "outputId": "ae5f50f2-e06d-40be-94f5-40335b2259e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "second_split[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "313470a0",
      "metadata": {
        "id": "313470a0",
        "outputId": "20c25e26-56b9-44c7-dbfc-c4a5b5a05688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Set',\n",
              " 'in',\n",
              " 'a',\n",
              " 'dystopian',\n",
              " 'future',\n",
              " 'where',\n",
              " 'humanity',\n",
              " 'is',\n",
              " 'embroiled',\n",
              " 'in',\n",
              " 'a',\n",
              " 'catastrophic',\n",
              " 'blight',\n",
              " 'and',\n",
              " 'famine,',\n",
              " 'the',\n",
              " 'film',\n",
              " 'follows',\n",
              " 'a',\n",
              " 'group',\n",
              " 'of',\n",
              " 'astronauts',\n",
              " 'who',\n",
              " 'travel',\n",
              " 'through',\n",
              " 'a',\n",
              " 'wormhole',\n",
              " 'near',\n",
              " 'Saturn',\n",
              " 'in',\n",
              " 'search',\n",
              " 'of',\n",
              " 'a',\n",
              " 'new',\n",
              " 'home',\n",
              " 'for',\n",
              " 'humankind.']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "third_split = second_split[2].split(\" \")\n",
        "third_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f01cdda",
      "metadata": {
        "id": "4f01cdda"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}